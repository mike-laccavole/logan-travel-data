{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Make-necessary-imports\" data-toc-modified-id=\"Make-necessary-imports-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Make necessary imports</a></span></li><li><span><a href=\"#Scrape-www.massport.com-for-PDF-links\" data-toc-modified-id=\"Scrape-www.massport.com-for-PDF-links-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Scrape <code>www.massport.com</code> for PDF links</a></span></li><li><span><a href=\"#Define-function-to-isolate-month-and-year\" data-toc-modified-id=\"Define-function-to-isolate-month-and-year-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Define function to isolate <code>month</code> and <code>year</code></a></span></li><li><span><a href=\"#Capture-relevant-information-and-append-to-new-dataframe\" data-toc-modified-id=\"Capture-relevant-information-and-append-to-new-dataframe-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Capture relevant information and append to new dataframe</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "import io\n",
    "from bs4 import BeautifulSoup\n",
    "from PyPDF2 import PdfFileReader\n",
    "from pdfreader import SimplePDFViewer\n",
    "import urllib\n",
    "import tabula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape `www.massport.com` for PDF links\n",
    "\n",
    "Embedded in the URL below are links to all the PDFs that we'd like to scrape for data. This step will isolate all the URLs so that each PDF can be accessed individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base URL, create BeautifulSoup instance\n",
    "url = requests.get('https://www.massport.com/logan-airport/about-logan/airport-statistics/')\n",
    "soup = BeautifulSoup(url.content, 'html')\n",
    "\n",
    "# Create empty list to house all PDF links\n",
    "pdfs = []\n",
    "\n",
    "# Loop through all 'a' instances of 'noopener', scrape PDF link and append to empty list above\n",
    "for a in soup.find_all('a', rel = 'noopener'):\n",
    "    href = a['href']\n",
    "    if href[-3:] == 'pdf':\n",
    "        pdfs.append(href)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function to isolate `month` and `year`\n",
    "\n",
    "Scraping the PDF for its content will essentially dump a long, messy string into the notebook. The funciton below works by looking for a unique word in the string, in this case `Summary`, after which the `month` and `year` data is always referenced (this was determined after doing some testing and examining each PDF's string content).\n",
    "\n",
    "Isolating the `month` and `year` will make for valuable data, as we need a reference point in time for which the number of `domestic travelers` and `international travelers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_month_and_year(string):\n",
    "    \n",
    "    # Eliminate spaces, double spaces, and hyphens in the string\n",
    "    string = string.replace(' ', '')\n",
    "    string = string.replace('  ', '')\n",
    "    string = string.replace('-', '')\n",
    "    \n",
    "    # Isolate portion of string adjacent to the word \"summary\" + create blank string\n",
    "    x = string.find('Summary') + len('Summary')\n",
    "    y = ''\n",
    "    \n",
    "    # Loop through portion of string where 'Summary' begins\n",
    "    for i in range(x, x + 30):\n",
    "        \n",
    "        # Isolate date + year\n",
    "        character = string[i]\n",
    "        if character.isalnum() == True:\n",
    "            y += character\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capture relevant information and append to new dataframe\n",
    "\n",
    "We want to capture the `month + year`, `domestic passengers`, and `international passengers`. The dataframe will be simple with just 3 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create empty dataframe\n",
    "flights = pd.DataFrame(columns = ['Term', 'Domestic Passengers', 'International Passengers'])\n",
    "pdf_base_url = 'https://www.massport.com'\n",
    "\n",
    "# Create 3 empty lists\n",
    "terms = []\n",
    "domestic = []\n",
    "international = []\n",
    "\n",
    "# Loop through PDF lins\n",
    "for individual_url in pdfs:\n",
    "    pdf_url = pdf_base_url + individual_url\n",
    "    \n",
    "    # Use requests library to extract string text from PDF\n",
    "    response = requests.get(pdf_url)\n",
    "    with io.BytesIO(response.content) as f:\n",
    "        pdf = PdfFileReader(f)\n",
    "        # numpage for the number page\n",
    "        numpage=0\n",
    "        page = pdf.getPage(numpage)\n",
    "        page_content = page.extractText()     \n",
    "        page_content\n",
    "        \n",
    "        # Call 'find_month_and_year' function\n",
    "        term = find_month_and_year(page_content)\n",
    "        terms.append(term)\n",
    "    \n",
    "    # Try to read the data in the PDF using Tabula library\n",
    "    try:\n",
    "        table = tabula.read_pdf(pdf_url, multiple_tables=False, encoding = 'latin1', pages ='all')\n",
    "        df = table[0]\n",
    "    \n",
    "    # If that doesn't work, use the same library with manual PDF measurements (see below)\n",
    "    except:\n",
    "        table = tabula.read_pdf(pdf_url, multiple_tables=True, guess = False,\n",
    "                                area = (130.99, 30.64, 540.39, 533.67), stream = True, encoding = 'latin1', pages ='all')\n",
    "    \n",
    "    # Isolate dataframe and relevant data, append to appropriate list\n",
    "    df = table[0]\n",
    "    df.rename(columns = {list(df)[0]: 'Flights'}, inplace = True)\n",
    "    df.rename(columns = {list(df)[1]: 'Current Month'}, inplace = True)\n",
    "\n",
    "    \n",
    "    domestic_index = df[df['Flights'] == 'Total Domestic Passengers'].index[0]\n",
    "    international_index = df[df['Flights'] == 'Total International Passengers'].index[0]\n",
    "    \n",
    "    domestic_passengers = df[df['Flights'] == 'Total Domestic Passengers']['Current Month'][domestic_index]\n",
    "    domestic_passengers = domestic_passengers.replace(',', '')\n",
    "    domestic_passengers = int(domestic_passengers)\n",
    "    \n",
    "    international_passengers = df[df['Flights'] == 'Total International Passengers']['Current Month'][international_index]\n",
    "    international_passengers = international_passengers.replace(',', '')\n",
    "    international_passengers = int(international_passengers)\n",
    "    \n",
    "    domestic.append(domestic_passengers)\n",
    "    international.append(international_passengers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new dataframe\n",
    "flights = pd.DataFrame(columns = ['Term', 'Domestic Passengers', 'International Passengers'])\n",
    "\n",
    "# Add data to the predefined columns in the dataframe\n",
    "flights['Term'] = terms[:len(terms) - 1]\n",
    "flights['Domestic Passengers'] = domestic\n",
    "flights['International Passengers'] = international\n",
    "\n",
    "# Check work\n",
    "flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "flights.to_csv('../datasets/logan_travel_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "373.333px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
